{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "969fdc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from os import getcwd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import twitter_samples \n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f08a48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcb8931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos = all_positive_tweets[4000:]\n",
    "train_pos = all_positive_tweets[:4000]\n",
    "test_neg = all_negative_tweets[4000:]\n",
    "train_neg = all_negative_tweets[:4000]\n",
    "\n",
    "# X['x_train'] = train_pos + train_neg \n",
    "# test_x = test_pos + test_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec3a230f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function str.index>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "040b6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array(train_pos + train_neg ), columns=['x_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "debe66d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.index.map(lambda idx: 1 if idx < 4000 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "53a68b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    " \n",
    "    stemmer = PorterStemmer()\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks\n",
    "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
    "                               reduce_len=True)\n",
    "    tweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "    tweets_clean = []\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in stopwords_english and  # remove stopwords\n",
    "                word not in string.punctuation):  # remove punctuation\n",
    "            # tweets_clean.append(word)\n",
    "            stem_word = stemmer.stem(word)  # stemming word\n",
    "            tweets_clean.append(stem_word)\n",
    "\n",
    "    return tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e89e0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews= \"\"\n",
    "i=0\n",
    "for review in df['x_train']:\n",
    "    words = process_tweet(review)\n",
    "    for word in words:\n",
    "        reviews = reviews + word +\" \"\n",
    "reviews_l = reviews.split()\n",
    "vocabulary = Counter(reviews_l)\n",
    "unique_words = list(vocabulary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cfe8c76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['followfriday',\n",
       " 'top',\n",
       " 'engag',\n",
       " 'member',\n",
       " 'commun',\n",
       " 'week',\n",
       " ':)',\n",
       " 'hey',\n",
       " 'jame',\n",
       " 'odd',\n",
       " ':/',\n",
       " 'pleas',\n",
       " 'call',\n",
       " 'contact',\n",
       " 'centr',\n",
       " '02392441234',\n",
       " 'abl',\n",
       " 'assist',\n",
       " 'mani',\n",
       " 'thank',\n",
       " 'listen',\n",
       " 'last',\n",
       " 'night',\n",
       " 'bleed',\n",
       " 'amaz',\n",
       " 'track',\n",
       " 'scotland',\n",
       " 'congrat',\n",
       " 'yeaaah',\n",
       " 'yipppi',\n",
       " 'accnt',\n",
       " 'verifi',\n",
       " 'rqst',\n",
       " 'succeed',\n",
       " 'got',\n",
       " 'blue',\n",
       " 'tick',\n",
       " 'mark',\n",
       " 'fb',\n",
       " 'profil',\n",
       " '15',\n",
       " 'day',\n",
       " 'one',\n",
       " 'irresist',\n",
       " 'flipkartfashionfriday',\n",
       " 'like',\n",
       " 'keep',\n",
       " 'love',\n",
       " 'custom',\n",
       " 'wait',\n",
       " 'long',\n",
       " 'hope',\n",
       " 'enjoy',\n",
       " 'happi',\n",
       " 'friday',\n",
       " 'lwwf',\n",
       " 'second',\n",
       " 'thought',\n",
       " '’',\n",
       " 'enough',\n",
       " 'time',\n",
       " 'dd',\n",
       " 'new',\n",
       " 'short',\n",
       " 'enter',\n",
       " 'system',\n",
       " 'sheep',\n",
       " 'must',\n",
       " 'buy',\n",
       " 'jgh',\n",
       " 'go',\n",
       " 'bayan',\n",
       " ':d',\n",
       " 'bye',\n",
       " 'act',\n",
       " 'mischiev',\n",
       " 'etl',\n",
       " 'layer',\n",
       " 'in-hous',\n",
       " 'wareh',\n",
       " 'app',\n",
       " 'katamari',\n",
       " 'well',\n",
       " '…',\n",
       " 'name',\n",
       " 'impli',\n",
       " ':p',\n",
       " 'influenc',\n",
       " 'big',\n",
       " '...',\n",
       " 'juici',\n",
       " 'selfi',\n",
       " 'follow',\n",
       " 'perfect',\n",
       " 'alreadi',\n",
       " 'know',\n",
       " \"what'\",\n",
       " 'great',\n",
       " 'opportun',\n",
       " 'junior',\n",
       " 'triathlet',\n",
       " 'age',\n",
       " '12',\n",
       " '13',\n",
       " 'gatorad',\n",
       " 'seri',\n",
       " 'get',\n",
       " 'entri',\n",
       " 'lay',\n",
       " 'greet',\n",
       " 'card',\n",
       " 'rang',\n",
       " 'print',\n",
       " 'today',\n",
       " 'job',\n",
       " ':-)',\n",
       " \"friend'\",\n",
       " 'lunch',\n",
       " 'yummm',\n",
       " 'nostalgia',\n",
       " 'tb',\n",
       " 'ku',\n",
       " 'id',\n",
       " 'conflict',\n",
       " 'help',\n",
       " \"here'\",\n",
       " 'screenshot',\n",
       " 'work',\n",
       " 'hi',\n",
       " 'liv',\n",
       " 'hello',\n",
       " 'need',\n",
       " 'someth',\n",
       " 'u',\n",
       " 'fm',\n",
       " 'twitter',\n",
       " '—',\n",
       " 'sure',\n",
       " 'thing',\n",
       " 'dm',\n",
       " 'x',\n",
       " \"i'v\",\n",
       " 'heard',\n",
       " 'four',\n",
       " 'season',\n",
       " 'pretti',\n",
       " 'dope',\n",
       " 'penthous',\n",
       " 'obv',\n",
       " 'gobigorgohom',\n",
       " 'fun',\n",
       " \"y'all\",\n",
       " 'yeah',\n",
       " 'suppos',\n",
       " 'lol',\n",
       " 'chat',\n",
       " 'bit',\n",
       " 'youth',\n",
       " '💅🏽',\n",
       " '💋',\n",
       " 'seen',\n",
       " 'year',\n",
       " 'rest',\n",
       " 'goe',\n",
       " 'quickli',\n",
       " 'bed',\n",
       " 'music',\n",
       " 'fix',\n",
       " 'dream',\n",
       " 'spiritu',\n",
       " 'ritual',\n",
       " 'festiv',\n",
       " 'népal',\n",
       " 'begin',\n",
       " 'line-up',\n",
       " 'left',\n",
       " 'see',\n",
       " 'sarah',\n",
       " 'send',\n",
       " 'us',\n",
       " 'email',\n",
       " 'bitsy@bitdefender.com',\n",
       " \"we'll\",\n",
       " 'asap',\n",
       " 'kik',\n",
       " 'hatessuc',\n",
       " '32429',\n",
       " 'kikm',\n",
       " 'lgbt',\n",
       " 'tinder',\n",
       " 'nsfw',\n",
       " 'akua',\n",
       " 'cumshot',\n",
       " 'come',\n",
       " 'hous',\n",
       " 'nsn_supplement',\n",
       " 'effect',\n",
       " 'press',\n",
       " 'releas',\n",
       " 'distribut',\n",
       " 'result',\n",
       " 'link',\n",
       " 'remov',\n",
       " 'pressreleas',\n",
       " 'newsdistribut',\n",
       " 'bam',\n",
       " 'bestfriend',\n",
       " 'lot',\n",
       " 'warsaw',\n",
       " '<3',\n",
       " 'x46',\n",
       " 'everyon',\n",
       " 'watch',\n",
       " 'documentari',\n",
       " 'earthl',\n",
       " 'youtub',\n",
       " 'support',\n",
       " 'buuut',\n",
       " 'oh',\n",
       " 'look',\n",
       " 'forward',\n",
       " 'visit',\n",
       " 'next',\n",
       " 'letsgetmessi',\n",
       " 'jo',\n",
       " 'make',\n",
       " 'feel',\n",
       " 'better',\n",
       " 'never',\n",
       " 'anyon',\n",
       " 'kpop',\n",
       " 'flesh',\n",
       " 'good',\n",
       " 'girl',\n",
       " 'best',\n",
       " 'wish',\n",
       " 'reason',\n",
       " 'epic',\n",
       " 'soundtrack',\n",
       " 'shout',\n",
       " 'ad',\n",
       " 'video',\n",
       " 'playlist',\n",
       " 'would',\n",
       " 'dear',\n",
       " 'jordan',\n",
       " 'okay',\n",
       " 'fake',\n",
       " 'gameplay',\n",
       " ';)',\n",
       " 'haha',\n",
       " 'im',\n",
       " 'kid',\n",
       " 'stuff',\n",
       " 'exactli',\n",
       " 'product',\n",
       " 'line',\n",
       " 'etsi',\n",
       " 'shop',\n",
       " 'check',\n",
       " 'vacat',\n",
       " 'recharg',\n",
       " 'normal',\n",
       " 'charger',\n",
       " 'asleep',\n",
       " 'talk',\n",
       " 'sooo',\n",
       " 'someon',\n",
       " 'text',\n",
       " 'ye',\n",
       " 'bet',\n",
       " \"he'll\",\n",
       " 'fit',\n",
       " 'hear',\n",
       " 'speech',\n",
       " 'piti',\n",
       " 'green',\n",
       " 'garden',\n",
       " 'midnight',\n",
       " 'sun',\n",
       " 'beauti',\n",
       " 'canal',\n",
       " 'dasvidaniya',\n",
       " 'till',\n",
       " 'scout',\n",
       " 'sg',\n",
       " 'futur',\n",
       " 'wlan',\n",
       " 'pro',\n",
       " 'confer',\n",
       " 'asia',\n",
       " 'chang',\n",
       " 'lollipop',\n",
       " '🍭',\n",
       " 'nez',\n",
       " 'agnezmo',\n",
       " 'oley',\n",
       " 'mama',\n",
       " 'stand',\n",
       " 'stronger',\n",
       " 'god',\n",
       " 'misti',\n",
       " 'babi',\n",
       " 'cute',\n",
       " 'woohoo',\n",
       " \"can't\",\n",
       " 'sign',\n",
       " 'yet',\n",
       " 'still',\n",
       " 'think',\n",
       " 'mka',\n",
       " 'liam',\n",
       " 'access',\n",
       " 'welcom',\n",
       " 'stat',\n",
       " 'arriv',\n",
       " '1',\n",
       " 'unfollow',\n",
       " 'via',\n",
       " 'surpris',\n",
       " 'figur',\n",
       " 'happybirthdayemilybett',\n",
       " 'sweet',\n",
       " 'talent',\n",
       " '2',\n",
       " 'plan',\n",
       " 'drain',\n",
       " 'gotta',\n",
       " 'timezon',\n",
       " 'parent',\n",
       " 'proud',\n",
       " 'least',\n",
       " 'mayb',\n",
       " 'sometim',\n",
       " 'grade',\n",
       " 'al',\n",
       " 'grand',\n",
       " 'manila_bro',\n",
       " 'chosen',\n",
       " 'let',\n",
       " 'around',\n",
       " '..',\n",
       " 'side',\n",
       " 'world',\n",
       " 'eh',\n",
       " 'take',\n",
       " 'care',\n",
       " 'final',\n",
       " 'fuck',\n",
       " 'weekend',\n",
       " 'real',\n",
       " 'x45',\n",
       " 'join',\n",
       " 'hushedcallwithfraydo',\n",
       " 'gift',\n",
       " 'yeahhh',\n",
       " 'hushedpinwithsammi',\n",
       " 'event',\n",
       " 'might',\n",
       " 'luv',\n",
       " 'realli',\n",
       " 'appreci',\n",
       " 'share',\n",
       " 'wow',\n",
       " 'tom',\n",
       " 'gym',\n",
       " 'monday',\n",
       " 'invit',\n",
       " 'scope',\n",
       " 'friend',\n",
       " 'nude',\n",
       " 'sleep',\n",
       " 'birthday',\n",
       " 'want',\n",
       " 't-shirt',\n",
       " 'cool',\n",
       " 'haw',\n",
       " 'phela',\n",
       " 'mom',\n",
       " 'obvious',\n",
       " 'princ',\n",
       " 'charm',\n",
       " 'stage',\n",
       " 'luck',\n",
       " 'tyler',\n",
       " 'hipster',\n",
       " 'glass',\n",
       " 'marti',\n",
       " 'glad',\n",
       " 'done',\n",
       " 'afternoon',\n",
       " 'read',\n",
       " 'kahfi',\n",
       " 'finish',\n",
       " 'ohmyg',\n",
       " 'yaya',\n",
       " 'dub',\n",
       " 'stalk',\n",
       " 'ig',\n",
       " 'gondooo',\n",
       " 'moo',\n",
       " 'tologooo',\n",
       " 'becom',\n",
       " 'detail',\n",
       " 'zzz',\n",
       " 'xx',\n",
       " 'physiotherapi',\n",
       " 'hashtag',\n",
       " '💪',\n",
       " 'monica',\n",
       " 'miss',\n",
       " 'sound',\n",
       " 'morn',\n",
       " \"that'\",\n",
       " 'x43',\n",
       " 'definit',\n",
       " 'tri',\n",
       " 'tonight',\n",
       " 'took',\n",
       " 'advic',\n",
       " 'treviso',\n",
       " 'concert',\n",
       " 'citi',\n",
       " 'countri',\n",
       " \"i'll\",\n",
       " 'start',\n",
       " 'fine',\n",
       " 'gorgeou',\n",
       " 'xo',\n",
       " 'oven',\n",
       " 'roast',\n",
       " 'garlic',\n",
       " 'oliv',\n",
       " 'oil',\n",
       " 'dri',\n",
       " 'tomato',\n",
       " 'basil',\n",
       " 'centuri',\n",
       " 'tuna',\n",
       " 'right',\n",
       " 'back',\n",
       " 'atchya',\n",
       " 'even',\n",
       " 'almost',\n",
       " 'chanc',\n",
       " 'cheer',\n",
       " 'po',\n",
       " 'ice',\n",
       " 'cream',\n",
       " 'agre',\n",
       " '100',\n",
       " 'heheheh',\n",
       " 'that',\n",
       " 'point',\n",
       " 'stay',\n",
       " 'home',\n",
       " 'soon',\n",
       " 'promis',\n",
       " 'web',\n",
       " 'whatsapp',\n",
       " 'volta',\n",
       " 'funcionar',\n",
       " 'com',\n",
       " 'iphon',\n",
       " 'jailbroken',\n",
       " 'later',\n",
       " '34',\n",
       " 'min',\n",
       " 'leia',\n",
       " 'appear',\n",
       " 'hologram',\n",
       " 'r2d2',\n",
       " 'w',\n",
       " 'messag',\n",
       " 'obi',\n",
       " 'wan',\n",
       " 'sit',\n",
       " 'luke',\n",
       " 'inter',\n",
       " '3',\n",
       " 'ucl',\n",
       " 'arsen',\n",
       " 'small',\n",
       " 'team',\n",
       " 'pass',\n",
       " '🚂',\n",
       " 'dewsburi',\n",
       " 'railway',\n",
       " 'station',\n",
       " 'dew',\n",
       " 'west',\n",
       " 'yorkshir',\n",
       " '430',\n",
       " 'smh',\n",
       " '9:25',\n",
       " 'live',\n",
       " 'strang',\n",
       " 'imagin',\n",
       " 'megan',\n",
       " 'masaantoday',\n",
       " 'a4',\n",
       " 'shweta',\n",
       " 'tripathi',\n",
       " '5',\n",
       " '20',\n",
       " 'kurta',\n",
       " 'half',\n",
       " 'number',\n",
       " 'wsalelov',\n",
       " 'ah',\n",
       " 'larri',\n",
       " 'anyway',\n",
       " 'kinda',\n",
       " 'goood',\n",
       " 'life',\n",
       " 'enn',\n",
       " 'could',\n",
       " 'warmup',\n",
       " '15th',\n",
       " 'bath',\n",
       " 'dum',\n",
       " 'andar',\n",
       " 'ram',\n",
       " 'sampath',\n",
       " 'sona',\n",
       " 'mohapatra',\n",
       " 'samantha',\n",
       " 'edward',\n",
       " 'mein',\n",
       " 'tulan',\n",
       " 'razi',\n",
       " 'wah',\n",
       " 'josh',\n",
       " 'alway',\n",
       " 'smile',\n",
       " 'pictur',\n",
       " '16.20',\n",
       " 'giveitup',\n",
       " 'given',\n",
       " 'ga',\n",
       " 'subsidi',\n",
       " 'initi',\n",
       " 'propos',\n",
       " 'delight',\n",
       " 'yesterday',\n",
       " 'x42',\n",
       " 'lmaoo',\n",
       " 'song',\n",
       " 'ever',\n",
       " 'shall',\n",
       " 'littl',\n",
       " 'throwback',\n",
       " 'outli',\n",
       " 'island',\n",
       " 'cheung',\n",
       " 'chau',\n",
       " 'mui',\n",
       " 'wo',\n",
       " 'total',\n",
       " 'differ',\n",
       " 'kfckitchentour',\n",
       " 'kitchen',\n",
       " 'clean',\n",
       " \"i'm\",\n",
       " 'cusp',\n",
       " 'test',\n",
       " 'water',\n",
       " 'reward',\n",
       " 'arummzz',\n",
       " \"let'\",\n",
       " 'drive',\n",
       " 'travel',\n",
       " 'yogyakarta',\n",
       " 'jeep',\n",
       " 'indonesia',\n",
       " 'instamood',\n",
       " 'wanna',\n",
       " 'skype',\n",
       " 'may',\n",
       " 'nice',\n",
       " 'friendli',\n",
       " 'pretend',\n",
       " 'film',\n",
       " 'congratul',\n",
       " 'winner',\n",
       " 'cheesydelight',\n",
       " 'contest',\n",
       " 'address',\n",
       " 'guy',\n",
       " 'market',\n",
       " '24/7',\n",
       " '14',\n",
       " 'hour',\n",
       " 'leav',\n",
       " 'without',\n",
       " 'delay',\n",
       " 'actual',\n",
       " 'easi',\n",
       " 'guess',\n",
       " 'train',\n",
       " 'wd',\n",
       " 'shift',\n",
       " 'engin',\n",
       " 'etc',\n",
       " 'sunburn',\n",
       " 'peel',\n",
       " 'blog',\n",
       " 'huge',\n",
       " 'warm',\n",
       " '☆',\n",
       " 'complet',\n",
       " 'triangl',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " 'sight',\n",
       " 'smthng',\n",
       " 'fr',\n",
       " 'hug',\n",
       " 'xoxo',\n",
       " 'uu',\n",
       " 'jaann',\n",
       " 'topnewfollow',\n",
       " 'connect',\n",
       " 'wonder',\n",
       " 'made',\n",
       " 'fluffi',\n",
       " 'insid',\n",
       " 'pirouett',\n",
       " 'moos',\n",
       " 'trip',\n",
       " 'philli',\n",
       " 'decemb',\n",
       " \"i'd\",\n",
       " 'dude',\n",
       " 'x41',\n",
       " 'question',\n",
       " 'flaw',\n",
       " 'pain',\n",
       " 'negat',\n",
       " 'strength',\n",
       " 'went',\n",
       " 'solo',\n",
       " 'move',\n",
       " 'fav',\n",
       " 'nirvana',\n",
       " 'smell',\n",
       " 'teen',\n",
       " 'spirit',\n",
       " 'rip',\n",
       " 'ami',\n",
       " 'winehous',\n",
       " 'coupl',\n",
       " 'tomhiddleston',\n",
       " 'elizabetholsen',\n",
       " 'yaytheylookgreat',\n",
       " 'goodnight',\n",
       " 'vid',\n",
       " 'wake',\n",
       " 'gonna',\n",
       " 'shoot',\n",
       " 'itti',\n",
       " 'bitti',\n",
       " 'teeni',\n",
       " 'bikini',\n",
       " 'much',\n",
       " '4th',\n",
       " 'togeth',\n",
       " 'end',\n",
       " 'xfile',\n",
       " 'content',\n",
       " 'rain',\n",
       " 'fabul',\n",
       " 'fantast',\n",
       " '♡',\n",
       " 'jb',\n",
       " 'forev',\n",
       " 'belieb',\n",
       " 'nighti',\n",
       " 'bug',\n",
       " 'bite',\n",
       " 'bracelet',\n",
       " 'idea',\n",
       " 'foundri',\n",
       " 'game',\n",
       " 'sens',\n",
       " 'pic',\n",
       " 'ef',\n",
       " 'phone',\n",
       " 'woot',\n",
       " 'derek',\n",
       " 'use',\n",
       " 'parkshar',\n",
       " 'gloucestershir',\n",
       " 'aaaahhh',\n",
       " 'man',\n",
       " 'traffic',\n",
       " 'stress',\n",
       " 'reliev',\n",
       " \"how'r\",\n",
       " 'arbeloa',\n",
       " 'turn',\n",
       " '17',\n",
       " 'omg',\n",
       " 'say',\n",
       " 'europ',\n",
       " 'rise',\n",
       " 'find',\n",
       " 'hard',\n",
       " 'believ',\n",
       " 'uncount',\n",
       " 'coz',\n",
       " 'unlimit',\n",
       " 'cours',\n",
       " 'teamposit',\n",
       " 'aldub',\n",
       " '☕',\n",
       " 'rita',\n",
       " 'info',\n",
       " \"we'd\",\n",
       " 'way',\n",
       " 'boy',\n",
       " 'x40',\n",
       " 'true',\n",
       " 'sethi',\n",
       " 'high',\n",
       " 'exe',\n",
       " 'skeem',\n",
       " 'saam',\n",
       " 'peopl',\n",
       " 'polit',\n",
       " 'izzat',\n",
       " 'wese',\n",
       " 'trust',\n",
       " 'khawateen',\n",
       " 'k',\n",
       " 'sath',\n",
       " 'mana',\n",
       " 'kar',\n",
       " 'deya',\n",
       " 'sort',\n",
       " 'smart',\n",
       " 'hair',\n",
       " 'tbh',\n",
       " 'jacob',\n",
       " 'g',\n",
       " 'upgrad',\n",
       " 'tee',\n",
       " 'famili',\n",
       " 'person',\n",
       " 'two',\n",
       " 'convers',\n",
       " 'onlin',\n",
       " 'mclaren',\n",
       " 'fridayfeel',\n",
       " 'tgif',\n",
       " 'squar',\n",
       " 'enix',\n",
       " 'bissmillah',\n",
       " 'ya',\n",
       " 'allah',\n",
       " \"we'r\",\n",
       " 'socent',\n",
       " 'startup',\n",
       " 'drop',\n",
       " 'your',\n",
       " 'arnd',\n",
       " 'town',\n",
       " 'basic',\n",
       " 'piss',\n",
       " 'cup',\n",
       " 'also',\n",
       " 'terribl',\n",
       " 'complic',\n",
       " 'discuss',\n",
       " 'snapchat',\n",
       " 'lynettelow',\n",
       " 'kikmenow',\n",
       " 'snapm',\n",
       " 'hot',\n",
       " 'amazon',\n",
       " 'kikmeguy',\n",
       " 'defin',\n",
       " 'grow',\n",
       " 'sport',\n",
       " 'rt',\n",
       " 'rakyat',\n",
       " 'write',\n",
       " 'sinc',\n",
       " 'mention',\n",
       " 'fli',\n",
       " 'fish',\n",
       " 'promot',\n",
       " 'post',\n",
       " 'cyber',\n",
       " 'ourdaughtersourprid',\n",
       " 'mypapamyprid',\n",
       " 'papa',\n",
       " 'coach',\n",
       " 'posit',\n",
       " 'kha',\n",
       " 'atleast',\n",
       " 'x39',\n",
       " 'mango',\n",
       " \"lassi'\",\n",
       " \"monty'\",\n",
       " 'marvel',\n",
       " 'though',\n",
       " 'suspect',\n",
       " 'meant',\n",
       " '24',\n",
       " 'hr',\n",
       " 'touch',\n",
       " 'kepler',\n",
       " '452b',\n",
       " 'chalna',\n",
       " 'hai',\n",
       " 'thankyou',\n",
       " 'hazel',\n",
       " 'food',\n",
       " 'brooklyn',\n",
       " 'pta',\n",
       " 'awak',\n",
       " 'okayi',\n",
       " 'awww',\n",
       " 'ha',\n",
       " 'doc',\n",
       " 'splendid',\n",
       " 'spam',\n",
       " 'folder',\n",
       " 'amount',\n",
       " 'nigeria',\n",
       " 'claim',\n",
       " 'rted',\n",
       " 'leg',\n",
       " 'hurt',\n",
       " 'bad',\n",
       " 'mine',\n",
       " 'saturday',\n",
       " 'thaaank',\n",
       " 'puhon',\n",
       " 'happinesss',\n",
       " 'tnc',\n",
       " 'prior',\n",
       " 'notif',\n",
       " 'fat',\n",
       " 'co',\n",
       " 'probabl',\n",
       " 'ate',\n",
       " 'yuna',\n",
       " 'tamesid',\n",
       " '´',\n",
       " 'googl',\n",
       " 'account',\n",
       " 'scouser',\n",
       " 'everyth',\n",
       " 'zoe',\n",
       " 'mate',\n",
       " 'liter',\n",
       " \"they'r\",\n",
       " 'samee',\n",
       " 'edgar',\n",
       " 'updat',\n",
       " 'log',\n",
       " 'bring',\n",
       " 'abe',\n",
       " 'meet',\n",
       " 'x38',\n",
       " 'sigh',\n",
       " 'dreamili',\n",
       " 'pout',\n",
       " 'eye',\n",
       " 'quacketyquack',\n",
       " 'funni',\n",
       " 'happen',\n",
       " 'phil',\n",
       " 'em',\n",
       " 'del',\n",
       " 'rodder',\n",
       " 'els',\n",
       " 'play',\n",
       " 'newest',\n",
       " 'gamejam',\n",
       " 'irish',\n",
       " 'literatur',\n",
       " 'inaccess',\n",
       " \"kareena'\",\n",
       " 'fan',\n",
       " 'brain',\n",
       " 'dot',\n",
       " 'braindot',\n",
       " 'fair',\n",
       " 'rush',\n",
       " 'either',\n",
       " 'brandi',\n",
       " '18',\n",
       " 'carniv',\n",
       " 'men',\n",
       " 'put',\n",
       " 'mask',\n",
       " 'xavier',\n",
       " 'forneret',\n",
       " 'jennif',\n",
       " 'site',\n",
       " 'free',\n",
       " '50.000',\n",
       " '8',\n",
       " 'ball',\n",
       " 'pool',\n",
       " 'coin',\n",
       " 'edit',\n",
       " 'trish',\n",
       " '♥',\n",
       " 'grate',\n",
       " 'three',\n",
       " 'comment',\n",
       " 'wakeup',\n",
       " 'besid',\n",
       " 'dirti',\n",
       " 'sex',\n",
       " 'lmaooo',\n",
       " '😤',\n",
       " 'loui',\n",
       " \"he'\",\n",
       " 'throw',\n",
       " 'caus',\n",
       " 'inspir',\n",
       " 'ff',\n",
       " 'twoof',\n",
       " 'gr8',\n",
       " 'wkend',\n",
       " 'kind',\n",
       " 'exhaust',\n",
       " 'word',\n",
       " 'cheltenham',\n",
       " 'area',\n",
       " 'kale',\n",
       " 'crisp',\n",
       " 'ruin',\n",
       " 'x37',\n",
       " 'open',\n",
       " 'worldwid',\n",
       " 'outta',\n",
       " 'sfvbeta',\n",
       " 'vantast',\n",
       " 'xcylin',\n",
       " 'bundl',\n",
       " 'show',\n",
       " 'internet',\n",
       " 'price',\n",
       " 'realisticli',\n",
       " 'pay',\n",
       " 'net',\n",
       " 'educ',\n",
       " 'power',\n",
       " 'weapon',\n",
       " 'nelson',\n",
       " 'mandela',\n",
       " 'recent',\n",
       " 'j',\n",
       " 'chenab',\n",
       " 'flow',\n",
       " 'pakistan',\n",
       " 'incredibleindia',\n",
       " 'teenchoic',\n",
       " 'choiceinternationalartist',\n",
       " 'superjunior',\n",
       " 'caught',\n",
       " 'first',\n",
       " 'salmon',\n",
       " 'super-blend',\n",
       " 'project',\n",
       " 'youth@bipolaruk.org.uk',\n",
       " 'awesom',\n",
       " 'stream',\n",
       " 'alma',\n",
       " 'mater',\n",
       " 'highschoolday',\n",
       " 'clientvisit',\n",
       " 'faith',\n",
       " 'christian',\n",
       " 'school',\n",
       " 'lizaminnelli',\n",
       " 'upcom',\n",
       " 'uk',\n",
       " '😄',\n",
       " 'singl',\n",
       " 'hill',\n",
       " 'everi',\n",
       " 'beat',\n",
       " 'wrong',\n",
       " 'readi',\n",
       " 'natur',\n",
       " 'pefumeri',\n",
       " 'workshop',\n",
       " 'neal',\n",
       " 'yard',\n",
       " 'covent',\n",
       " 'tomorrow',\n",
       " 'fback',\n",
       " 'indo',\n",
       " ...]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['followfriday']\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b592933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_features(tweet, freqs):\n",
    "  \n",
    "    word_l = process_tweet(tweet)\n",
    "    \n",
    "    # 3 elements in the form of a 1 x 3 vector\n",
    "    x = np.zeros((1, 3)) \n",
    "    \n",
    "    #bias term is set to 1\n",
    "    x[0,0] = 1 \n",
    "    \n",
    "\n",
    "    \n",
    "    # loop through each word in the list of words\n",
    "    for word in word_l:\n",
    "        \n",
    "        # increment the word count for the positive label 1\n",
    "        \n",
    "        x[0,1] += freqs.get((word,1),0)\n",
    "        \n",
    "        # increment the word count for the negative label 0\n",
    "        x[0,2] += freqs.get((word,0),0)\n",
    "\n",
    "    assert(x.shape == (1, 3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8235cb6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15976\\1343500356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtmp1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x_train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15976\\3878238043.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(tweet, freqs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mword_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprocess_tweet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# 3 elements in the form of a 1 x 3 vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15976\\2948474544.py\u001b[0m in \u001b[0;36mprocess_tweet\u001b[1;34m(tweet)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mstopwords_english\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# remove stock market tickers like $GE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'\\$\\w*'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# remove old style retweet text \"RT\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'^RT[\\s]+'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mMatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 210\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "tmp1 = extract_features(df['x_train'], vocabulary)\n",
    "print(tmp1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
